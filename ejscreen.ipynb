{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/edgi-govdata-archiving/ECHO_modules.git &>/dev/null;\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !git clone https://github.com/edgi-govdata-archiving/EEW-EJScreen.git\n",
    "    # Geopandas is an open source library for working with geographic data using the\n",
    "    #   data structures library \"pandas\" (common in Python for data processing).\n",
    "    #   (https://geopandas.org/)\n",
    "    !pip install pygeos &>/dev/null;\n",
    "    !pip install geopandas  &>/dev/null;\n",
    "    %mv /content/EEW-EJScreen/state-fips-codes.csv /content\n",
    "    %mkdir /content/census-shapefiles\n",
    "    %mv /content/EEW-EJScreen/census-shapefiles/census2010.db /content/census-shapefiles/census2010.db\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Enter a state and congressional districe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the state and CD. Then you can run all.\n",
    "state = 'KS'\n",
    "cd = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use shapefiles to construct an initial outline map of the district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import folium\n",
    "\n",
    "url = \"https://theunitedstates.io/districts/cds/2012/{}-{}/shape.geojson\".format( state, str(cd))       \n",
    "cd_boundary = geopandas.read_file(url)\n",
    "bounds = cd_boundary.bounds\n",
    "map=folium.Map(location=((bounds.miny+bounds.maxy)/2., (bounds.minx+bounds.maxx)/2.), zoom_level=4)\n",
    "# map.fit_bounds(bounds)\n",
    "w = folium.GeoJson( cd_boundary, name = \"Congressional Districts\").add_to(map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Look up the state's two-digit FIPS code from a local CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"state-fips-codes.csv\")\n",
    "df = df[df['State_Code'] == state]\n",
    "state_fips = str(df['FIPS_Code'].iloc[0]).zfill(2)\n",
    "state_fips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use the FIPS_Code for the state to identify the EJ Screen records just for this state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ECHO_modules.get_data import get_echo_data\n",
    "\n",
    "sql = 'SELECT count(*) FROM \"EJSCREEN_2021_USPR\"'\n",
    "df = get_echo_data(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ECHO_modules.get_data import get_echo_data\n",
    "\n",
    "select_columns = '\"ID\", \"P_LDPNT_D2\", \"P_DSLPM_D2\", \"P_CANCR_D2\", '\n",
    "select_columns += '\"P_RESP_D2\", \"P_PTRAF_D2\", \"P_PWDIS_D2\", '\n",
    "select_columns += '\"P_PNPL_D2\", \"P_PRMP_D2\", \"P_PTSDF_D2\", '\n",
    "select_columns += '\"P_OZONE_D2\", \"P_PM25_D2\"'\n",
    "\n",
    "sql = 'select {} from \"EJSCREEN_2021_USPR\" where DIV(\"ID\", 10000000000) = {}' \n",
    "sql = sql.format(select_columns, state_fips)\n",
    "ej_state_df = get_echo_data(sql)\n",
    "# Rename the ID field to match the field in the census data block group.\n",
    "ej_state_df.rename(columns={'ID':'GEOID'}, inplace=True)\n",
    "ej_state_df['GEOID'] = ej_state_df['GEOID'].astype(int)\n",
    "ej_state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get census shapefiles for all block groups in the state\n",
    "ej_state_df now contains the EJScreen data for all census block groups in the state.\n",
    "We want to identify just those in our CD.\n",
    "For that we need the bounding polygon of the CD (we have that in cd_boundary), and an interior \n",
    "point of the census block, for each census block identified by ID in ej_state_df.\n",
    "The interior point of the census block is (INTPTLAT, INTPTLON) within the census_block_groups table,\n",
    "in a SQLite database we've created. (See the census-shapefiles.ipynb notebook in the census-shapefiles\n",
    "directory.)\n",
    "Note: This will run acceptably fast with Jupyter Notebook on a local computer. SQLite on Google Colab is pretty slow, however. (It took 2 1/2 minutes to load Massachusetts.) Think of ways of making this faster. One way would be to load the content of census2010.db into\n",
    "the Stony Brook University PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"census-shapefiles/census2010.db\")\n",
    "\n",
    "bg_point_list = []\n",
    "for index, row in ej_state_df.iterrows():\n",
    "    # Use row['GEOID'] to look for the block group in the census db.\n",
    "    sql = 'select GEOID, INTPTLAT, INTPTLON from census_block_groups where GEOID=\\'{}\\''.format(row['GEOID'])\n",
    "    c = conn.cursor()\n",
    "    c.execute(sql)\n",
    "    block_group = c.fetchone()\n",
    "    bg_point_list.append(block_group)\n",
    "conn.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Identify the EJ Screen records within this CD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "bg_points_df = pd.DataFrame(bg_point_list, columns =['GEOID', 'INTPTLAT', 'INTPTLON'])\n",
    "bg_points_gdf = gpd.GeoDataFrame(bg_points_df, crs='epsg:4269',\n",
    "                    geometry=gpd.points_from_xy(bg_points_df.INTPTLON, bg_points_df.INTPTLAT))\n",
    "bg_points_gdf = bg_points_gdf.to_crs(4326)\n",
    "within_points = gpd.sjoin(bg_points_gdf, cd_boundary, op='within')\n",
    "within_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot the census block groups as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(within_points)):\n",
    "   folium.Marker(\n",
    "      location=[within_points.iloc[i]['INTPTLAT'], within_points.iloc[i]['INTPTLON']],\n",
    "      popup=within_points.iloc[i]['GEOID'],\n",
    "   ).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Filter the EJ Screen records to just those in the congressional district\n",
    "We have the census block groups in the within_points dataframe, and the EJ screen records for\n",
    "all census blocks in the state in ej_state_df. Filter ej_state_df where its ID field matches\n",
    "GEOID in within_points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_columns = ['GEOID', 'P_LDPNT_D2', 'P_DSLPM_D2', 'P_CANCR_D2', 'P_RESP_D2', 'P_PTRAF_D2', 'P_PWDIS_D2',\n",
    "     'P_PNPL_D2', 'P_PRMP_D2', 'P_PTSDF_D2', 'P_OZONE_D2', 'P_PM25_D2']\n",
    "\n",
    "ej_cd_df = within_points.merge(ej_state_df[ej_columns], on='GEOID')\n",
    "ej_cd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Compute means and standard deviations for each of the 11 EJ Screen metrics\n",
    "Select only the 11 columns in EJ Screen for national percentiles of the census block group among all groups in the U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['P_LDPNT_D2', 'P_DSLPM_D2', 'P_CANCR_D2', 'P_RESP_D2', 'P_PTRAF_D2', 'P_PWDIS_D2', \n",
    "           'P_PNPL_D2', 'P_PRMP_D2', 'P_PTSDF_D2', 'P_OZONE_D2', 'P_PM25_D2']\n",
    "ej_cd_df[columns] = ej_cd_df[columns].apply(pd.to_numeric)\n",
    "ej_cd_scores = ej_cd_df[columns]\n",
    "means = pd.DataFrame(ej_cd_scores.mean())\n",
    "new_columns=['Lead paint', 'Diesel', 'Air toxics cancer', 'Air toxics resp',\n",
    "             'Traffic', 'Water discharge', 'NPL sites', 'RMP facilities',\n",
    "             'TSDF facilities', 'Ozone', 'PM2.5']\n",
    "means = means.set_axis(new_columns, axis=0)\n",
    "\n",
    "stdev = pd.DataFrame(ej_cd_scores.std())\n",
    "stdev = stdev.set_axis(new_columns, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Write out the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_cd_scores.to_csv('ejscreen-{}{}-percentiles.csv'.format(state, cd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Put the scores for the census block groups into 20 5-percent bins. \n",
    "Then count how many block groups have gone into each bin.\n",
    "Assign each bin the value of the mid-point of its range--2.5, 7.5, ... 92.5, 97.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.melt(ej_cd_scores)\n",
    "df2['value2'] = pd.to_numeric(df2['value'], errors='ignore')\n",
    "df2['bins'] = pd.cut(df2['value2'], bins=[0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100])\n",
    "\n",
    "newdf = pd.DataFrame(columns=['metric', 'value', 'count'])\n",
    "for metric in columns:\n",
    "    tempdf = df2[df2['variable'] == metric]\n",
    "    for bin in tempdf['bins'].unique():\n",
    "        try:\n",
    "            midpoint = (bin.left + bin.right)/2\n",
    "            tempdf2 = tempdf[tempdf['bins'] == bin]\n",
    "            count = 2 * tempdf2['value'].count()\n",
    "            new_row = {'metric':metric, 'value':midpoint, 'count':float(count)}\n",
    "            # breakpoint()\n",
    "            newdf = newdf.append(new_row,ignore_index=True)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "newdf       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Plot the bins of census block group EJ Screen scores\n",
    "Plot the count of census blocks in the 20 5-percent bins by assigning a dot whose size\n",
    "is proportional to the count. Also plot a line showing one standard deviation of the\n",
    "data around the mean. \n",
    "\n",
    "This standard deviation is a measure of the inequality within the district--if\n",
    "all census block groups were equal the standard deviation would be zero; if there are \n",
    "many very high (i.e. bad) EJ scores and also many other low EJ scores, the standard\n",
    "deviation will be large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 5]\n",
    "# Set up with a higher resolution screen (useful on Mac)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "means.plot(kind='bar', alpha=0., yerr = stdev)\n",
    "# means_plus_stdev.plot(kind='bar', alpha=0.3)\n",
    "plt.scatter(x=newdf['metric'], y=newdf['value'], sizes=newdf['count'],\n",
    "           color='Green')\n",
    "\n",
    "plt.title(\"EJ Screen Index Percentiles for {}, District {}\".format(state,cd))\n",
    "plt.xlabel(\"EJ Screen Categories\")\n",
    "plt.ylabel(\"Census Blocks in National Percentiles\\n and Standard Deviation\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(labels=new_columns,rotation=60)\n",
    "# plt.ylim(0,100)\n",
    "# plt.axhline(y = 50, color = 'r', linestyle = '-')\n",
    "filename = \"graph-{}-{}.png\".format(state, cd)\n",
    "plt.savefig(filename, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below here doesn't currently work.\n",
    "To do: \n",
    "    Compute these std dev figures for all CDs, into ej_screen_cd_stdev_rankings.csv. That is produced by the all_regions.ipynb notebook.\n",
    "    These are just ideas for techniques.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = pd.read_csv('ej_screen_cd_stdev_rankings.csv')\n",
    "ydf = xdf[['Lead_Paint.Pct','Diesel.Pct','Air_toxics_cancer.Pct','Air_toxics_resp.Pct',\n",
    "                   'Traffic.Pct','Water_discharge.Pct','NPL_sites.Pct','RMP_facilities.Pct',\n",
    "                  'TSDF_facilities.Pct','Ozone.Pct','PM2.5.Pct','State','CD']]\n",
    "zdf = ydf.loc[ydf['State'] == state]\n",
    "rank_df = zdf.loc[zdf['CD'] == int(cd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "grades = ['A','B','C','D','F']\n",
    "\n",
    "columns = list(rank_df)\n",
    "for i in columns:\n",
    "    nm = rank_df[i].name\n",
    "    if nm != 'State' and nm != 'CD':\n",
    "        s = rank_df[i]\n",
    "        value = s[s.index[0]]\n",
    "        grade = 'None'\n",
    "        if np.issubdtype(rank_df[i].dtype, np.number):\n",
    "            value = int(value/0.2)\n",
    "            grade = grades[value]\n",
    "        print('{} - Grade for \"fairness\" in the district is {} ({} percentile nationally)'.format(\n",
    "            nm, grade, int(s[s.index[0]]*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{: >30}\".format(\"Hansen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
